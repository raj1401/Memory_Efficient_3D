Utilizing 2D Attention-Based Models for Memory Efficient 3D Reconstruction
==========================================================================

This repository contains the official implementation of my MS Thesis **"Utilizing 2D Attention-Based Models for Memory Efficient 3D Reconstruction"**.

üìå Overview
-----------

3D Gaussian Splatting (3DGS) has recently emerged as a powerful representation for real-time 3D scene reconstruction and rendering. While it provides high visual fidelity and efficiency, it often requires **millions of Gaussians**, leading to **large memory/storage overhead**.

This work introduces a **novel spatial grouping + 2D attention framework** that compresses 3DGS representations while preserving high visual quality. Our method can reduce memory usage by **up to 16√ó** without significant loss in rendering fidelity.

* * * * *

üöÄ Key Contributions
--------------------

-   **Gaussian Importance Ranking**\
    A new pruning strategy ranks Gaussians based on opacity, volume, and luminance, retaining only the most important ones.

-   **Spatial Grouping**\
    Gaussians are rearranged into a structured 2D matrix so that adjacent rows correspond to nearby points in 3D space, enabling effective use of attention mechanisms.

-   **2D Attention-Based Compression Model**\
    A lightweight model combining **Transformer encoders, convolutional downscaling, and pooling** to learn compact scene representations.

-   **Supervised Initialization**\
    Pre-training on curated Gaussian subsets stabilizes convergence and improves training efficiency.

* * * * *

üìä Experimental Results
-----------------------

-   **Dataset**: Evaluated on the CO3D dataset (hydrant category, ~224 scenes).

-   **Compression Ratios**: Achieved **2√ó, 4√ó, 8√ó, and 16√ó** compression.

-   **Metrics**:

    -   At 16√ó compression, reconstructions maintain strong fidelity:

        -   PSNR ‚âà 33 dB

        -   SSIM ‚âà 0.95

        -   LPIPS ‚âà 0.07

-   **Qualitative Findings**: Even at **16√ó compression**, scenes preserve overall geometry and structure, with only minor loss of fine details (e.g., text/smudges on hydrants).

* * * * *

üß© Methodology
--------------

1.  **3DGS Generation**:\
    Scenes reconstructed with Nerfstudio + COLMAP, producing Gaussian splats.

2.  **Preprocessing & Pruning**:\
    Normalize scene size ‚Üí prune excess Gaussians ‚Üí duplicate if under-sampled.

3.  **Spatial Grouping**:\
    Partition space into voxels ‚Üí merge into regions ‚Üí reorder Gaussians for locality.

4.  **Compression Model**:

    -   Sliding-window self-attention over Gaussian tokens.

    -   1D convolutions with pooling for downscaling.

    -   Self-attention + FFN for reconstruction and rendering.

5.  **Training**:

    -   Optimizer: Adam

    -   Loss: MSE over rendered images from 8 viewpoints

* * * * *

üìà Results Summary
------------------

| Compression | PSNR (Test) | SSIM | LPIPS |
| --- | --- | --- | --- |
| 2√ó | 46.4 dB | 0.99 | 0.02 |
| 4√ó | 38.4 dB | 0.97 | 0.04 |
| 8√ó | 34.5 dB | 0.96 | 0.06 |
| 16√ó | 32.4 dB | 0.95 | 0.07 |

* * * * *

üèÜ Conclusion
-------------

Our framework demonstrates that **attention-based compression** is highly effective for reducing the size of 3DGS scenes. By leveraging both **short- and long-range dependencies** among Gaussians, we can achieve **up to 16√ó compression** with negligible degradation in visual quality, enabling scalable and memory-efficient 3D reconstruction for downstream applications such as **AR/VR, robotics, and digital content creation**.
